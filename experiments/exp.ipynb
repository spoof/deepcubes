{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import editdistance\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import json\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm, linear_model\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import FastText\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Tagset(Enum):\n",
    "    UPOS = 1\n",
    "    MYSTEM = 2\n",
    "\n",
    "class ModelType(Enum):\n",
    "    W2V = 1\n",
    "    FASTTEXT = 2\n",
    "\n",
    "folder_path = '/mnt/data/embedding_models/'\n",
    "config = [\n",
    "    {'path': folder_path+'araneum_upos_skipgram_300_2_2018.vec', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'araneum_upos_skipgram_600_2_2017.bin', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'news_mystem_skipgram_1000_20_2015.bin', 'type': ModelType.W2V, 'tagset': Tagset.MYSTEM},\n",
    "    {'path': folder_path+'news_upos_cbow_300_2_2017.bin', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'news_upos_cbow_600_2_2018.vec', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'ruscorpora_mystem_cbow_300_2_2015.bin', 'type': ModelType.W2V, 'tagset': Tagset.MYSTEM}, \n",
    "    {'path': folder_path+'ruscorpora_upos_skipgram_300_10_2017.bin', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'ruscorpora_upos_skipgram_300_5_2018.vec', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'ruscorpora_upos_skipgram_600_10_2017.bin', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'ruwikiruscorpora-nobigrams_upos_skipgram_300_5_2018.vec', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'ruwikiruscorpora-superbigrams_skipgram_300_2_2018.vec', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'ruwikiruscorpora_upos_cbow_300_20_2017.bin', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'ruwikiruscorpora_upos_skipgram_300_2_2018.vec', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'taiga_upos_skipgram_300_2_2018.vec', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'web_mystem_skipgram_500_2_2015.bin', 'type': ModelType.W2V, 'tagset': Tagset.MYSTEM},\n",
    "    {'path': folder_path+'web_upos_cbow_300_20_2017.bin', 'type': ModelType.W2V, 'tagset': Tagset.UPOS},\n",
    "    {'path': folder_path+'araneum_none_fasttextcbow_300_5_2018/araneum_none_fasttextcbow_300_5_2018.model', 'type': ModelType.FASTTEXT, 'tagset': None},\n",
    "    {'path': folder_path+'araneum_none_fasttextskipgram_300_5_2018/araneum_none_fasttextskipgram_300_5_2018.model', 'type': ModelType.FASTTEXT, 'tagset': None},\n",
    "]\n",
    "# ruwikiruscorpora_mystem_cbow_500_2_2015.bin.gz - damaged, can't unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'красивый_A'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = Mystem()\n",
    "\n",
    "mystem_to_upos = {\n",
    "    \"A\": \"ADJ\",\n",
    "    \"ADV\": \"ADV\",\n",
    "    \"ADVPRO\": \"ADV\",\n",
    "    \"ANUM\": \"ADJ\",\n",
    "    \"APRO\": \"DET\",\n",
    "    \"COM\": \"ADJ\",\n",
    "    \"CONJ\": \"SCONJ\",\n",
    "    \"INTJ\": \"INTJ\",\n",
    "    \"NONLEX\": \"X\",\n",
    "    \"NUM\": \"NUM\",\n",
    "    \"PART\": \"PART\",\n",
    "    \"PR\": \"ADP\",\n",
    "    \"S\": \"NOUN\",\n",
    "    \"SPRO\": \"PRON\",\n",
    "    \"UNKN\": \"X\",\n",
    "    \"V\": \"VERB\",\n",
    "}\n",
    "\n",
    "def tag(word, tagset=None):\n",
    "    \"\"\"Get lexema from word and add tag\"\"\"\n",
    "    if not tagset:\n",
    "        return word.lower()\n",
    "        \n",
    "    processed = stemmer.analyze(word)[0]\n",
    "    \n",
    "    try:\n",
    "        lemma = processed[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "\n",
    "        pos = processed[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "        pos = pos.split('=')[0].strip()\n",
    "\n",
    "        if tagset == Tagset.UPOS:\n",
    "            return \"{}_{}\".format(lemma, mystem_to_upos[pos])\n",
    "        else:\n",
    "            return \"{}_{}\".format(lemma, pos)\n",
    "    except:\n",
    "        return \"word\"\n",
    "\n",
    "tag(\"красивый\", Tagset.MYSTEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    return \" \".join([\n",
    "        tag(word) for word in text.split()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vector(text, model, dim, tagset, model_type=ModelType.W2V):                                          \n",
    "    vector = np.zeros(dim)\n",
    "    words = [tag(word, tagset) for word in text.split()]\n",
    "\n",
    "    words_in_model = 0  \n",
    "    \n",
    "    if model_type == ModelType.FASTTEXT:\n",
    "        for word in words:                                               \n",
    "            if word in model.wv.vocab:                                              \n",
    "                vector += model[word]                           \n",
    "                words_in_model += 1      \n",
    "    else:\n",
    "        for word in words:                                               \n",
    "            if word in model:                                              \n",
    "                vector += model.get_vector(word)                           \n",
    "                words_in_model += 1    \n",
    "\n",
    "    if words_in_model > 0:                                                  \n",
    "        vector /= words_in_model                                            \n",
    "\n",
    "    return vector "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"/home/vera/projects/profile-identity/data/dialog-ru-ru.json\", \"r\") as infile:\n",
    "    data = json.load(infile)\n",
    "    \n",
    "for line in config:\n",
    "    DIM = 0\n",
    "    if line['type'] == ModelType.FASTTEXT:\n",
    "        model = FastText.load(line['path'])\n",
    "        DIM = len(model[next(iter(model.wv.vocab.keys()))])\n",
    "    elif line['type'] == ModelType.W2V:\n",
    "        isBin = True\n",
    "        if '.vec' in line['path']:\n",
    "            print('vec')\n",
    "            isBin = False\n",
    "        \n",
    "        model = KeyedVectors.load_word2vec_format(\n",
    "            line['path'],\n",
    "            binary=isBin,\n",
    "            unicode_errors='ignore'\n",
    "        )\n",
    "        DIM = len(model.get_vector(next(iter(model.vocab.keys()))))\n",
    "    print(line['path'])\n",
    "    print(DIM)\n",
    "    X, Y = [], []\n",
    "\n",
    "    for label, category in enumerate(data):\n",
    "        for q in category[\"questions\"]:\n",
    "            Y.append(label)\n",
    "            X.append(calculate_vector(q, model, DIM, line['tagset'], line['type']))\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "#     name = line['path'].split('/')[-1].split('.')[0]\n",
    "#     print(name)\n",
    "#     models_data_list.append({'name': name, 'x': X, 'y': Y})\n",
    "    \n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    parameters = {'metric':('manhattan', 'euclidean', 'chebyshev',\n",
    "                            'minkowski'), 'n_neighbors':[2, 3, 5, 10, 20]}\n",
    "    parameters_svm = {'kernel':('linear', 'polynomial', 'rbf')}\n",
    "#     grd = GridSearchCV(clf, parameters, cv = loo)\n",
    "    grd = GridSearchCV(svm, parameters_svm, cv = loo)\n",
    "    grd.fit(X, Y)\n",
    "    print(grd.best_score_)\n",
    "    print(grd.best_params_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Handlers.SIG_DFL: 0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from signal import signal, SIGPIPE, SIG_DFL\n",
    "signal(SIGPIPE, SIG_DFL)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, metric=\"manhattan\")\n",
    "svm_cl = svm.SVC()\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "ovr = OneVsRestClassifier(linear_model.LogisticRegression(C=1e5))\n",
    "\n",
    "parameters_knn = {'metric':('manhattan', 'euclidean', 'chebyshev', 'minkowski'), 'n_neighbors':[2, 3, 5, 10, 20]}\n",
    "parameters_svm = {'kernel':('linear', 'poly', 'rbf')}\n",
    "# parameters_logreg = {'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'), 'multi_class': ('ovr', 'multinomial')}\n",
    "parameters_logreg = {'solver': ('newton-cg', 'liblinear')}\n",
    "\n",
    "loo = LeaveOneOut()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = list()\n",
    "models_list.append({'model': knn, 'parameters': parameters_knn})\n",
    "models_list.append({'model': svm_cl, 'parameters': parameters_svm})\n",
    "models_list.append({'model': logreg, 'parameters': parameters_logreg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data_list = list()\n",
    "with open('models_data.pickle', 'rb') as handle:\n",
    "    models_data_list = pickle.load(handle)\n",
    "\n",
    "best_of_all = dict()\n",
    "best_of_all['score'] =0\n",
    "for line in models_data_list:\n",
    "    for mod in models_list:\n",
    "        X = line['x']\n",
    "        Y = line['y']\n",
    "        y_true, y_pred = [], []\n",
    "\n",
    "    #     grd = GridSearchCV(clf, parameters, cv = loo)\n",
    "        grd = GridSearchCV(mod['model'], mod['parameters'], cv = loo)\n",
    "        grd.fit(X, Y)\n",
    "        print(line['name'])\n",
    "        print(grd.best_score_)\n",
    "        print(grd.best_params_)\n",
    "\n",
    "        if grd.best_score_ > best_of_all['score']:\n",
    "            best_of_all['score'] = grd.best_score_\n",
    "            best_of_all['name'] = line['name']\n",
    "            best_of_all['params'] = grd.best_params_\n",
    "\n",
    "print(best_of_all)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
